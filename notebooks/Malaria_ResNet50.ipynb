{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malaria Blood Cell Classification with ResNet-50 (TensorFlow/Keras)\n",
    "\n",
    "This notebook trains and evaluates a ResNet-50 model to classify blood cell images as Parasitized vs Uninfected using a manifest-based `tf.data` pipeline (no image copying).\n",
    "\n",
    "- Dataset path: `/Users/jitesh/Downloads/cell_images` (Parasitized/ and Uninfected/)\n",
    "- Manifests: `data/manifests/train.csv`, `val.csv`, `test.csv`\n",
    "- Image size: 224, Batch size: 32\n",
    "- Two-phase training: head, then fine-tune last ResNet block\n",
    "- Metrics: Accuracy, Precision, Recall, F1, ROC-AUC; Confusion Matrix saved to `reports/figures/confusion_matrix.png`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in a fresh environment, uncomment the next lines to install missing packages.\n",
    "# %pip install --upgrade pip\n",
    "# %pip install -r ../requirements.txt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from src.datasets_tf import get_datasets_from_manifests\n",
    "from src.model_tf import build_resnet50\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = Path('/Users/jitesh/Downloads/cell_images')\n",
    "MANIFEST_DIR = Path('../data/manifests')\n",
    "MODELS_DIR = Path('../models')\n",
    "REPORTS_DIR = Path('../reports')\n",
    "FIG_DIR = REPORTS_DIR / 'figures'\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_HEAD = 10\n",
    "EPOCHS_FT = 10\n",
    "LR_HEAD = 1e-4\n",
    "LR_FT = 1e-5\n",
    "PATIENCE = 4\n",
    "SEED = 42\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_OUT = MODELS_DIR / 'best_resnet50.h5'\n",
    "METRICS_TXT = REPORTS_DIR / 'metrics.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create manifests (if missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate manifests only if they do not exist yet.\n",
    "if not (MANIFEST_DIR / 'train.csv').exists():\n",
    "    MANIFEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    import subprocess, sys\n",
    "    print('Creating manifests...')\n",
    "    cmd = [sys.executable, '-m', 'src.create_manifests', '--raw_dir', str(RAW_DIR), '--out_dir', str(MANIFEST_DIR), '--val_size', '0.15', '--test_size', '0.15', '--seed', str(SEED)]\n",
    "    print(' '.join(cmd))\n",
    "    res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    print(res.stdout)\n",
    "    if res.returncode != 0:\n",
    "        print(res.stderr)\n",
    "        raise RuntimeError('Failed to create manifests')\n",
    "else:\n",
    "    print('Manifests already exist at', MANIFEST_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build datasets from manifests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds, class_names = get_datasets_from_manifests(str(MANIFEST_DIR), img_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED)\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model and train (head phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, base = build_resnet50(input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(LR_HEAD),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_auc', mode='max', patience=PATIENCE, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_auc', mode='max', factor=0.5, patience=max(1, PATIENCE-1), min_lr=1e-6),\n",
    "    ModelCheckpoint(filepath=str(MODEL_OUT), monitor='val_auc', mode='max', save_best_only=True)\n",
    "]\n",
    "\n",
    "history_head = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_HEAD, callbacks=callbacks)\n",
    "MODEL_OUT.exists(), MODEL_OUT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune last ResNet block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze last conv block (conv5*)\n",
    "base.trainable = True\n",
    "trainable = False\n",
    "for layer in base.layers:\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D) and 'conv5' in layer.name:\n",
    "        trainable = True\n",
    "    layer.trainable = trainable\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(LR_FT),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "history_ft = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_FT, callbacks=callbacks)\n",
    "model.save(MODEL_OUT)\n",
    "MODEL_OUT.exists(), MODEL_OUT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = model.evaluate(val_ds, return_dict=True)\n",
    "test_metrics = model.evaluate(test_ds, return_dict=True)\n",
    "val_metrics, test_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed metrics and confusion matrix (Test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect ground truth and predictions\n",
    "y_true = []\n",
    "y_prob = []\n",
    "for batch, labels in test_ds:\n",
    "    y_true.extend(labels.numpy().reshape(-1).astype(int).tolist())\n",
    "    y_prob.extend(model.predict(batch, verbose=0).reshape(-1).tolist())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_prob = np.array(y_prob)\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "try:\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "except Exception:\n",
    "    auc = float('nan')\n",
    "\n",
    "print({'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1, 'auc': auc})\n",
    "\n",
    "# Save metrics\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "with open(METRICS_TXT, 'w') as f:\n",
    "    f.write(f'Accuracy: {acc}\n')\n",
    "    f.write(f'Precision: {prec}\n')\n",
    "    f.write(f'Recall: {rec}\n')\n",
    "    f.write(f'F1: {f1}\n')\n",
    "    f.write(f'ROC-AUC: {auc}\n')\n",
    "print('Saved metrics to', METRICS_TXT)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Parasitized','Uninfected'],\n",
    "            yticklabels=['Parasitized','Uninfected'])\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "fig_path = FIG_DIR / 'confusion_matrix.png'\n",
    "plt.savefig(fig_path, dpi=150)\n",
    "plt.show()\n",
    "print('Saved confusion matrix to', fig_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
